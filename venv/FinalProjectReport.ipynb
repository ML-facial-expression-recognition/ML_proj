{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Final Project - Facial expression recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project proposal: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a facial recognition system from scratch which will finally recognize the emotion by  analysing images/videos. Our system will attempt to recognize six basic emotional expressions including fear, disgust, anger, surprise, happiness, and sadness introduced by Ekman[1]. Because the racial effect will occur in the process of facial recognition. We will also try to figure out how to detect races which may reduce the influence of the effect. \n",
    "/n    To make this system more interesting, we plan to transform the final result from the plain words into emoji. This means that the output will be an emoji that can represent the emotion and the race of the human.There may be other human-related information we can detect from static images and video sequences, like genders, ages, hair colors and so on. Facial expression and race will be the most important feature that we will focus on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Program Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocessing\n",
    "\n",
    "#### 2.1.1 get_train_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. tranverse all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_data():\n",
    "    file_path = '../img/CFDImages/'  # path of the file that stores the raw images\n",
    "    res = []\n",
    "    clss = ['A','B','L','W']\n",
    "\n",
    "    detector = face_feature.get_detector()\n",
    "    predictor = face_feature.get_predictor()\n",
    "\n",
    "    for (root, dirs, files) in os.walk(file_path, ):\n",
    "        for dir in dirs:\n",
    "            img_root = os.path.join(root, dir)\n",
    "            for img_name in os.listdir(img_root):\n",
    "                if img_name.endswith('N.jpg'):\n",
    "                    full_path = os.path.join(img_root,img_name)\n",
    "                    print(full_path)\n",
    "                    _,fts = face_feature.get_all_feature(full_path,detector,predictor)\n",
    "\n",
    "                    for ft in fts:\n",
    "                        cls = img_name[4]\n",
    "                        rj = [clss.index(cls)]\n",
    "                        for k in ft:\n",
    "                            rj.append(k)\n",
    "                        res.append(rj)\n",
    "                        print(len(res))\n",
    "    res = np.asarray(res)\n",
    "\n",
    "    save_path = '../img/CFDImages/'\n",
    "    if save_feature(save_path, res):\n",
    "        print(\"feature saved!\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. save features into feature.npy file, and format as below:\n",
    "    | label | features |\n",
    "    |   0   |   ...    |\n",
    "    |   1   |   ...    |\n",
    "    |  ...  |   ...    |\n",
    "            \n",
    "    label : multiclass {0,1,...};\n",
    "    features : get_face_feature in face_feature.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_feature(path, res):\n",
    "    try:\n",
    "        np.save(path+'feature', res)\n",
    "        return 1\n",
    "    except:\n",
    "        print(\"Error saving res\")\n",
    "        return 0\n",
    "\n",
    "def save_race_feature(path, res):\n",
    "    try:\n",
    "        np.save(path+'race', res)\n",
    "        return 1\n",
    "    except:\n",
    "        print(\"Error saving res\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. extract race features and save to into file\n",
    "get racial features from get_all_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_data():\n",
    "    file_path = '../img/CFDImages/'  # path of the file that stores the raw images\n",
    "    res = []\n",
    "    clss = ['A','B','L','W']\n",
    "\n",
    "    detector = face_feature.get_detector()\n",
    "    predictor = face_feature.get_predictor()\n",
    "\n",
    "    for (root, dirs, files) in os.walk(file_path, ):\n",
    "        for dir in dirs:\n",
    "            img_root = os.path.join(root, dir)\n",
    "            for img_name in os.listdir(img_root):\n",
    "                if img_name.endswith('N.jpg'):\n",
    "                    full_path = os.path.join(img_root,img_name)\n",
    "                    print(full_path)\n",
    "                    _,fts = face_feature.get_all_feature(full_path,detector,predictor)\n",
    "\n",
    "                    for ft in fts:\n",
    "                        cls = img_name[4]\n",
    "                        rj = [clss.index(cls)]\n",
    "                        for k in ft:\n",
    "                            rj.append(k)\n",
    "                        res.append(rj)\n",
    "                        print(len(res))\n",
    "    res = np.asarray(res)\n",
    "\n",
    "    save_path = '../img/CFDImages/'\n",
    "    if save_feature(save_path, res):\n",
    "        print(\"feature saved!\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 face_feature.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. get all features from path or camera;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_face_feature(path):\n",
    "    detector = get_detector()\n",
    "    predictor = get_predictor()\n",
    "    return get_all_feature(path,detector,predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_feature_from_camera(img, detector, predictor):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    faces = detector(gray_img, 0)\n",
    "\n",
    "    res_landmark = []\n",
    "    res_race = []\n",
    "    # get features\n",
    "    for (i, face) in enumerate(faces):\n",
    "        shape = predictor(gray_img, face)\n",
    "        fts = face_utils.shape_to_np(shape)\n",
    "\n",
    "        # square the faces and normalize the feature\n",
    "        norm = np.amax(fts, 0) - np.amin(fts, 0)\n",
    "        fts_norm = (fts - np.amin(fts, 0)) / norm\n",
    "        fts_ret = fts_norm.reshape((1, fts_norm.shape[0] * fts_norm.shape[1]), order='A').tolist()[0]\n",
    "        res_landmark.append(fts_ret)\n",
    "\n",
    "        # get skin color feature\n",
    "        std_landmark = [[37,38,42],[38,39,42],[38,39,41],[39,40,41],[2,29,30],[2,30,31],[2,3,32],[3,4,32]]\n",
    "        res_hsv = []\n",
    "        for tri in std_landmark:\n",
    "            # find a list of points that located inside the triangle\n",
    "            pts = get_pts_in_tri(fts, tri)\n",
    "\n",
    "            # find average hsv color space of points inside triangles\n",
    "            hsv = get_hsv_in_tri(img, pts)\n",
    "\n",
    "            for i in hsv:\n",
    "                res_hsv.append(i)\n",
    "\n",
    "        res_race.append(res_hsv)\n",
    "    return res_landmark, res_race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. The fuction get_detector() and get_predictor() are dependent on dlib library, defined as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detector():\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    return detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictor():\n",
    "    p = \"../img/face_landmarks.dat\"\n",
    "    predictor = dlib.shape_predictor(p)\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. help function used on reading images from path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_feature(path,detector,predictor):\n",
    "    img = cv2.imread(path)\n",
    "    return get_all_feature_from_camera(img, detector, predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. help function used on reading images from camera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_feature(path, detector, predictor):\n",
    "    # get the image\n",
    "    img = cv2.imread(path)\n",
    "    res = get_face_feature_from_camera(img, detector, predictor)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. set a landmark triangle from face points\n",
    "<img src=\"https://ibug.doc.ic.ac.uk/media/uploads/images/annotpics/figure_68_markup.jpg\" title=\"facefeatures\" width=\"500\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_landmark = [[37,38,42],[38,39,42],[38,39,41],[39,40,41],[2,29,30],[2,30,31],[2,3,32],[3,4,32]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f. extract racial features using hsv\n",
    "Define three fuctions to get **HSV** feature of skin colors\n",
    "*deter_in_tri, get_pts_in_tri, get_hsv_in_tri*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> number of feature landmarks: \n",
    ">    - expression: 68 x 2 = 136; \n",
    ">    - race: 3 x 8 = 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deter_in_tri(x,y,vers):\n",
    "    # determine if the point is in the triangle with three vertexes in vers\n",
    "    # get the result by determine whether the point is on the same side the with each point of the opposite arg\n",
    "    for i in range(3):\n",
    "        ab = vers.copy()\n",
    "        c = ab[i]\n",
    "        ab.pop(i)\n",
    "        if S(ab[0],ab[1],c)*S(ab[0],ab[1],[x,y])<0:\n",
    "            return 0\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pts_in_tri(fts,tri):\n",
    "    pts = []\n",
    "\n",
    "    vers = np.concatenate((np.asarray([fts[tri[0]-1,:]]),np.asarray([fts[tri[1]-1,:]]),np.asarray([fts[tri[2]-1,:]])),axis = 0)\n",
    "    xmin = np.min(vers,0)[0]\n",
    "    xmax = np.max(vers,0)[0]\n",
    "    ymin = np.min(vers,0)[1]\n",
    "    ymax = np.max(vers,0)[1]\n",
    "    vers = vers.tolist()\n",
    "\n",
    "    # check if pts are in the triangle\n",
    "    for x in range(xmin,xmax+1):\n",
    "        for y in range(ymin,ymax+1):\n",
    "            if deter_in_tri(x,y,vers) == 1:\n",
    "                pts.append([x,y])\n",
    "\n",
    "    return pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hsv_in_tri(img, pts):\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    num = len(pts)\n",
    "    h = 0\n",
    "    s = 0\n",
    "    v = 0\n",
    "\n",
    "    for pt in pts:\n",
    "        h = h + hsv_img[pt[0],pt[1],0]\n",
    "        s = s + hsv_img[pt[0],pt[1],1]\n",
    "        v = v + hsv_img[pt[0],pt[1],2]\n",
    "\n",
    "    return [h/num,s/num,v/num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 race_feature.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. extract features of different skin colors from camera capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_feature(path, detector, predictor):\n",
    "    img = cv2.imread(path)\n",
    "    res = get_race_feature_from_camera(img, detector, predictor)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. capture feature from camera frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_feature_from_camera(img, detector, predictor):\n",
    "    # get feature of the image\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # detect faces\n",
    "    faces = detector(gray_img, 0)\n",
    "\n",
    "    res = []\n",
    "    # get features\n",
    "    for (i, face) in enumerate(faces):\n",
    "        shape = predictor(gray_img, face)\n",
    "        fts = face_utils.shape_to_np(shape)\n",
    "        # for (x,y) in fts:\n",
    "        #     cv2.circle(img, (x, y), 2, (0, 255, 0), -1)\n",
    "\n",
    "        # square the faces and normalize the landmark feature\n",
    "        norm = np.amax(fts, 0) - np.amin(fts, 0)\n",
    "        fts_norm = (fts - np.amin(fts, 0)) / norm\n",
    "        fts_ret = fts_norm.reshape((1, fts_norm.shape[0] * fts_norm.shape[1]), order='A').tolist()[0]\n",
    "        res.append(fts_ret)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 get_train_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. get training data from files\n",
    "Extract features from get_face_feature():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    ...\n",
    "    fts = face_feature.get_face_feature(full_path, detector, predictor)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. get_race_data()\n",
    "Extract features from get_all_features():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_data():\n",
    "    ...\n",
    "     _,fts = face_feature.get_all_feature(full_path,detector,predictor)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 training_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. training data according to the input strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def lets_train(x,y,classifier,strategy):\n",
    "    # decomposition PCA\n",
    "    pca = decomposition.PCA(n_components=50).fit(x)\n",
    "    newx = x\n",
    "\n",
    "    if strategy == 'ova':\n",
    "        if classifier == 'svm':\n",
    "            clf = multiclass.OneVsRestClassifier(SVC(C = 1e2, gamma = 'auto')).fit(newx,y)\n",
    "        elif classifier == 'decisionTree':\n",
    "            clf = multiclass.OneVsRestClassifier(ensemble.BaggingClassifier(tree.DecisionTreeClassifier(max_depth=1),\n",
    "                                                                            n_estimators=200)).fit(newx,y)\n",
    "        elif classifier == 'logistic':\n",
    "            clf = multiclass.OneVsRestClassifier(LogisticRegression(C=1e8, penalty='l2',solver='newton-cg')).fit(newx,y)\n",
    "        elif classifier == 'mlp':\n",
    "            clf = multiclass.OneVsRestClassifier(neural_network.MLPClassifier(solver='sgd',activation = 'relu',\n",
    "                                                                              max_iter = 100,alpha = 1e-5,hidden_layer_sizes = (300,400,200,200),\n",
    "                                                                              verbose = True)).fit(newx,y)\n",
    "        else:\n",
    "            print(\"wrong classifier type in ova\")\n",
    "            return 0,1,0\n",
    "\n",
    "    elif strategy == 'ovo':\n",
    "        if classifier == 'svm':\n",
    "            clf = multiclass.OneVsOneClassifier(SVC(C = 1e2, gamma = 'auto')).fit(newx,y)\n",
    "        elif classifier == 'decisionTree':\n",
    "            clf = multiclass.OneVsOneClassifier(ensemble.BaggingClassifier(tree.DecisionTreeClassifier(max_depth=1),n_estimators=200)).fit(newx,y)\n",
    "        elif classifier == 'logistic':\n",
    "            clf = multiclass.OneVsOneClassifier(LogisticRegression(C=1e8,penalty='l2',solver='newton-cg')).fit(newx,y)\n",
    "        elif classifier == 'mlp':\n",
    "            clf = multiclass.OneVsRestClassifier(neural_network.MLPClassifier(solver='sgd',activation = 'logistic',\n",
    "                                                                              max_iter = 200,alpha = 1e-5,hidden_layer_sizes = (300,300),\n",
    "                                                                              verbose = True)).fit(newx,y)\n",
    "        else:\n",
    "            print(\"wrong classifier type in ovo\")\n",
    "            return 0, 1, 0\n",
    "\n",
    "    else:\n",
    "        print(\"wrong classifier strategy\")\n",
    "        return 0, 1, 0\n",
    "\n",
    "\n",
    "    err = np.sum(np.sign(abs(y.T-clf.predict(newx))))/y.shape[0]\n",
    "    return clf, err, pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. calculating error rate on testing data according to the classifier and PCA method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lets_test(x,y,clf,pca):\n",
    "    newx = x\n",
    "    test_res = clf.predict(newx)\n",
    "    err = np.sum(np.sign(abs(y.T-test_res)))/test_res.shape[0]\n",
    "    return test_res,err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. randomly choose 5/6 as training data and rest 1/6 as testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data(raw_data):\n",
    "    raw_data = raw_data.tolist()\n",
    "    n = len(raw_data)\n",
    "\n",
    "    # get a random sequence:\n",
    "    seq = np.arange(0,n,1)\n",
    "    rd.shuffle(seq)\n",
    "\n",
    "    # put data to each set\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    for i in range(n):\n",
    "        if seq[i] < n * 5/6:\n",
    "            train_data.append(raw_data[i])\n",
    "        else:\n",
    "            test_data.append(raw_data[i])\n",
    "\n",
    "    train_data = np.asarray(train_data)\n",
    "    test_data = np.asarray(test_data)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Main function: real time recognition from camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 rt_rec.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get trained model\n",
    "    feature_path = '../img/facesdb/feature.npy'\n",
    "    strategy = 'ova' # {'ova', 'ovo'}\n",
    "    classifier = 'svm' # {'svm', 'decisionTree','logistic','mlp'}\n",
    "    clf, pca = training_data.training_data(feature_path, strategy, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # get real time result\n",
    "    while(True):\n",
    "        _,img = cam.read()\n",
    "        x_offset = 100\n",
    "        y_offset = 250\n",
    "        ft = np.asarray(face_feature.get_face_feature_from_camera(img,detector,predictor))\n",
    "\n",
    "        if ft.shape[0] > 0:\n",
    "            for i in range(ft.shape[0]):\n",
    "                res = clf.predict(np.mat(ft[i,:]).A)\n",
    "\n",
    "                emoji = cv2.imread(emoji_paths[int(res)])\n",
    "                emoji = cv2.resize(emoji, (int(150), int(150)))\n",
    "\n",
    "                img = cv2.putText(img, expression[int(res)],(100,200),cv2.FONT_HERSHEY_SIMPLEX,3,(255,255,255),4)\n",
    "                img[y_offset: y_offset + emoji.shape[0], x_offset: x_offset + emoji.shape[1]] = emoji\n",
    "\n",
    "        cv2.imshow(\"camera\", img)\n",
    "\n",
    "        k = cv2.waitKey(5) & 0xFF\n",
    "        if k == 27:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Ekman P., Friesen W.V., Ellsworth P.Emotion in the Human Face: Guide-Lines for Research and an Integration of Findings: Guidelines for Research and an Integration of Findings.Pergamon; Berlin, Germany: 1972.\n",
    "\n",
    "2.database source: http://app.visgraf.impa.br/database/faces\n",
    "\n",
    "+ 300-W\n",
    "+ XM2VTS\n",
    "+ FRGC Ver.2\n",
    "+ CFD ver2.0.3: https://chicagofaces.org/\n",
    "+ C. Sagonas, E. Antonakos, G, Tzimiropoulos, S. Zafeiriou, M. Pantic. 300 faces In-the-wild challenge: Database and results. Image and Vision Computing (IMAVIS), Special Issue on Facial Landmark Localisation \"In-The-Wild\". 2016.\n",
    "\n",
    "3.face feature: https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/\n",
    "\n",
    "+ IMPA-FACE3D(the geometry and texture are correlated)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
